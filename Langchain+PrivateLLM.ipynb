{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KUX5gqP3yqG",
        "outputId": "8552c477-3917-4296-e8f1-8e39475e4c0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct 12 06:44:46 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   75C    P8    12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bdsOfmoCjsn",
        "outputId": "e111fc4d-5e08-4c32-f985-2ec8baabe434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://huggingface.github.io/autogptq-index/whl/cu118/\n",
            "Requirement already satisfied: auto-gptq in /usr/local/lib/python3.10/dist-packages (0.4.2+cu118)\n",
            "Requirement already satisfied: accelerate>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.23.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (2.14.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.23.5)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (2.0.1+cu118)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.4.0)\n",
            "Collecting transformers>=4.31.0 (from auto-gptq)\n",
            "  Obtaining dependency information for transformers>=4.31.0 from https://files.pythonhosted.org/packages/1a/d1/3bba59606141ae808017f6fde91453882f931957f125009417b87a281067/transformers-4.34.0-py3-none-any.whl.metadata\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl.metadata (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.5/121.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.19.0->auto-gptq) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.19.0->auto-gptq) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.19.0->auto-gptq) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.19.0->auto-gptq) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->auto-gptq) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->auto-gptq) (17.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers>=4.31.0->auto-gptq)\n",
            "  Obtaining dependency information for tokenizers<0.15,>=0.14 from https://files.pythonhosted.org/packages/a7/7b/c1f643eb086b6c5c33eef0c3752e37624bd23e4cbc9f1332748f1c6252d1/tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.8.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge->auto-gptq) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->auto-gptq) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->auto-gptq) (1.3.0)\n",
            "Using cached transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "Using cached tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.13.3\n",
            "    Uninstalling tokenizers-0.13.3:\n",
            "      Successfully uninstalled tokenizers-0.13.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.30.2\n",
            "    Uninstalling transformers-4.30.2:\n",
            "      Successfully uninstalled transformers-4.30.2\n",
            "Successfully installed tokenizers-0.14.1 transformers-4.34.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAa20D2e2tYk",
        "outputId": "457cd71d-99cd-426b-eabf-0b41f7c093ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement autogptq==0.2.2 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for autogptq==0.2.2\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "auto-gptq 0.4.2+cu118 requires transformers>=4.31.0, but you have transformers 4.30.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -Uqqq pip --progress-bar off\n",
        "!pip install -qqq langchain==0.0.228 --progress-bar off\n",
        "!pip install -qqq  chromadb==0.3.26 --progress-bar off\n",
        "!pip install -qqq  sentence-transformers==2.2.2 --progress-bar off\n",
        "!pip install -qqq  autogptq==0.2.2 --progress-bar off\n",
        "!pip install -qqq  einops==0.6.1 --progress-bar off\n",
        "!pip install -qqq  unstructured==0.8.0 --progress-bar off\n",
        "!pip install -qqq  transformers==4.30.2 --progress-bar off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9hpUx4j2Xt9"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import torch\n",
        "from auto_gptq import AutoGPTQForCausalLM\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from transformers import AutoTokenizer, GenerationConfig, TextStreamer, pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions_dir = Path(\"skyscanner\")\n",
        "questions_dir.mkdir(exist_ok=True, parents=True)\n",
        "def write_file(question, answer, file_path):\n",
        "    text = f\"\"\"\n",
        "Q: {question}\n",
        "A: {answer}\n",
        "\"\"\".strip()\n",
        "    with Path(questions_dir / file_path).open(\"w\") as text_file:\n",
        "        text_file.write(text)"
      ],
      "metadata": {
        "id": "ZT7pKFK56XoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_file(\n",
        "    question=\"Is there a database with material properties in Altair EDEM?\",\n",
        "    answer=\"\"\"\n",
        "    Yes, the Generic EDEM Material Model (GEMM) database contains thousands of material models representing a variety of materials like rocks, soils and ores.The GEMM Database is fully integrated into EDEM which means users can access a range of materials instantly and can fully set up materials for a simulation without being a DEM expert.\n",
        "    The GEMM database is now built into EDEM and includes even more material models!\n",
        "    In addition users have access to:\n",
        "    Soils starter pack: 8 models of soils including different range of compressibility and stickiness. These models make use of different physics models inbuilt in EDEM to model a range of soils from gravels to soft compressible soils.\n",
        "    Powder starter pack:   9 example material models focusing on small particle sizes and representing a range of powder-materials with different flow properties and compressibility.\n",
        "    \"\"\".strip(),\n",
        "        file_path=\"question_1.txt\",\n",
        ")\n",
        "\n",
        "write_file(\n",
        "    question=\"What's new in Altair SLC Version 4.4\",\n",
        "    answer=\"\"\"\n",
        "    Altair SLC version 4.4.1 onwards is available for purchase under Altair Units using Altair Licensing.\n",
        "\n",
        "The Altair SLC 4.4 GA release contains new features and enhancements, and maintenance updates to existing functionality. Here are just a few headline items.\n",
        "\n",
        "SAS Language Support\n",
        "Support for the ODS POWERPOINT output destination.\n",
        "Both the ODSLIST and ODSTEXT procedures now support the DATA option of the procedure statement, the CELLSTYLE statement and the TRANSLATE statement.\n",
        "The IMPORT procedure now supports the STARTCOL, ENDCOL, STARTROW, and ENDROW statements.\n",
        "The HTTP procedure now supports the DEBUG statement.\n",
        "The SGPANEL procedure now supports the TEXT statement.\n",
        "The SGPLOT procedure now supports the TEXT, XAXISTABLE, and YAXISTABLE statements.\n",
        "The LOGISTIC procedure now supports the UNITS statement.\n",
        "Support for the MCMC procedure.\n",
        "Support for the MDC procedure.\n",
        "Support for the OPTLP procedure.\n",
        "Support for the ORTHOREG procedure.\n",
        "Support for the VARMAX procedure.\n",
        "Bulk insert functionality can now be used with ODBC connections to a Google BigQuery database.\n",
        "Connections to a Snowflake database can now use Key Pair Authentication and federated authentication.\n",
        "\n",
        "Workflow\n",
        "A JSON Import block has been added to enable datasets in JSON-formatted files to be imported into a Workflow.\n",
        "A Parameter Import block has been added to enable parameters to be imported into a Workflow as a dataset.\n",
        "A Deduplicate block has been added to enable duplicate observations to be removed from an input dataset.\n",
        "A Text Transform block has been added to enable text variables in an input dataset to be modified.\n",
        "The Hub group now includes:\n",
        "A Program Inputs block that enables Workflow parameters to be used in an executable deployment services program.\n",
        "A Program Results block that provides the results of an executable deployment services program to a Workflow.\n",
        "The Hub Program block is superseded by the Program Inputs and Program Results for defining input variables to, and results from, a deployment services program.\n",
        "The Database Explorer view can now be used to connect to Google BigQuery, Teradata, and Hadoop database servers.\n",
        "Variables from a dataset can now be grouped together for faster selection of the same multiple variables in Workflow blocks.\n",
        "    \"\"\".strip(),\n",
        "        file_path=\"question_1.txt\",\n",
        ")"
      ],
      "metadata": {
        "id": "ibXUznzd6Ouq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "pzCfFEKZAwuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "RdHwVGtzAv3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nl23ZH1bKUjr",
        "outputId": "86b9e074-5bba-4638-ca41-758cbfde1482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_name_or_path = \"TheBloke/Nous-Hermes-13B-GPTQ\"\n",
        "# model_basename = \"nous-hermes-13b-GPTQ-4bit-128g.no-act.order\"\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
        "\n",
        "# model = AutoGPTQForCausalLM.from_quantized(\n",
        "#     model_name_or_path,\n",
        "#     model_basename=model_basename,\n",
        "#     use_safetensors=True,\n",
        "#     trust_remote_code=True,\n",
        "#     device=DEVICE\n",
        "# )\n",
        "\n",
        "model_name_or_path = \"TheBloke/Nous-Hermes-13B-GPTQ\"\n",
        "model_basename = \"model\"\n",
        "\n",
        "use_triton = False\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
        "\n",
        "model = AutoGPTQForCausalLM.from_quantized(model_name_or_path,\n",
        "        model_basename=model_basename,\n",
        "        use_safetensors=True,\n",
        "        trust_remote_code=True,\n",
        "        device=DEVICE,\n",
        "        use_triton=use_triton,\n",
        "        quantize_config=None)\n",
        "\n",
        "generation_config = GenerationConfig.from_pretrained(model_name_or_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeJOQg5_A9tC",
        "outputId": "6d96cf23-7700-4ac0-f2ed-f216f2d351ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:auto_gptq.nn_modules.fused_llama_mlp:skip module injection for FusedLlamaMLPForQuantizedModel not support integrate without triton yet.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = (\n",
        "    \"Which programming language is more suitable for a beginner: Python or Javascript?\"\n",
        ")\n",
        "\n",
        "prompt = f\"\"\"\n",
        "### Instruction: {question}\n",
        "### Response:\n",
        "\"\"\".strip()"
      ],
      "metadata": {
        "id": "-mW8h3HEClGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QBtiyciC2ME",
        "outputId": "436f9ac0-1f72-465e-d434-a90c5e826591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Instruction: Which programming language is more suitable for a beginner: Python or Javascript?\n",
            "### Response:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(DEVICE)\n",
        "with torch.inference_mode():\n",
        "  output = model.generate(inputs=input_ids, temperature=0.7, max_new_tokens=512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqxiYhZEJa83",
        "outputId": "34e4ba66-57a5-4be8-af4e-7f015c9d55ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.14 s, sys: 235 ms, total: 3.37 s\n",
            "Wall time: 3.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(output[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uemf0PZGKHGf",
        "outputId": "ab15654b-c2f2-422a-bbf4-2bf5212c490b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> ### Instruction: Which programming language is more suitable for a beginner: Python or Javascript?\n",
            "### Response:Both Python and Javascript are suitable for beginners, but Python is generally considered easier to learn and has a more straightforward syntax. Javascript is more commonly used for web development and can be more complex due to its interaction with HTML and CSS.</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-ePyQYnKeHU",
        "outputId": "584ab01e-de71-4bc0-b4d8-fe1845da0527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GenerationConfig {\n",
              "  \"_from_model_config\": true,\n",
              "  \"bos_token_id\": 1,\n",
              "  \"eos_token_id\": 2,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"transformers_version\": \"4.30.2\"\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "streamer = TextStreamer(\n",
        "    tokenizer, skip_prompt=True, skip_special_tokens=True, use_multiprocessing=False\n",
        ")"
      ],
      "metadata": {
        "id": "LvLkb8_nKnCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=2048,\n",
        "    temperature=0,\n",
        "    top_p=0.95,\n",
        "    repetition_penalty=1.15,\n",
        "    generation_config=generation_config,\n",
        "    streamer=streamer,\n",
        "    batch_size=1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoD2xKnOK3WK",
        "outputId": "cacf3714-9ee9-4dbe-845e-ba14ab35a62e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
            "pip install xformers.\n",
            "The model 'LlamaGPTQForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "id": "lqiwTNWMMDBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJYqL-4NMNS6",
        "outputId": "5c22add8-71a3-47d1-812b-6138c0a32d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python is generally considered to be more suitable for beginners due to its readability and simplicity compared to JavaScript.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jhgK3lwbMUIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"intfloat/multilingual-e5-base\",\n",
        "    model_kwargs={\"device\": DEVICE},\n",
        ")"
      ],
      "metadata": {
        "id": "7iUamh7BMUTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DirectoryLoader(\"./skyscanner/\", glob=\"**/*txt\")\n",
        "documents = loader.load()\n",
        "len(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cPsnLNZMUXp",
        "outputId": "edf26900-dce2-4425-a91c-a3af6657eefa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=512, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "TKgnJq7_MUbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c7de32e-aef9-4f3c-b1e0-b0777fd536eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 920, which is longer than the specified 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqGnRbCVN0IJ",
        "outputId": "35075e8b-dea0-4173-b002-66c447d01f5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content=\"Q: What's new in Altair SLC Version 4.4 A: Altair SLC version 4.4.1 onwards is available for purchase under Altair Units using Altair Licensing.\\n\\nThe Altair SLC 4.4 GA release contains new features and enhancements, and maintenance updates to existing functionality. Here are just a few headline items.\", metadata={'source': 'skyscanner/question_1.txt'})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db = Chroma.from_documents(texts, embeddings)"
      ],
      "metadata": {
        "id": "V083nU_jN0Ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db.similarity_search(\"flight search\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZv4pC8TN0Nb",
        "outputId": "4f764c2b-9418-401b-fcd3-e69125f9e76a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.db.index.hnswlib:Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"Q: What's new in Altair SLC Version 4.4 A: Altair SLC version 4.4.1 onwards is available for purchase under Altair Units using Altair Licensing.\\n\\nThe Altair SLC 4.4 GA release contains new features and enhancements, and maintenance updates to existing functionality. Here are just a few headline items.\", metadata={'source': 'skyscanner/question_1.txt'}),\n",
              " Document(page_content='SAS Language Support Support for the ODS POWERPOINT output destination. Both the ODSLIST and ODSTEXT procedures now support the DATA option of the procedure statement, the CELLSTYLE statement and the TRANSLATE statement. The IMPORT procedure now supports the STARTCOL, ENDCOL, STARTROW, and ENDROW statements. The HTTP procedure now supports the DEBUG statement. The SGPANEL procedure now supports the TEXT statement. The SGPLOT procedure now supports the TEXT, XAXISTABLE, and YAXISTABLE statements. The LOGISTIC procedure now supports the UNITS statement. Support for the MCMC procedure. Support for the MDC procedure. Support for the OPTLP procedure. Support for the ORTHOREG procedure. Support for the VARMAX procedure. Bulk insert functionality can now be used with ODBC connections to a Google BigQuery database. Connections to a Snowflake database can now use Key Pair Authentication and federated authentication.', metadata={'source': 'skyscanner/question_1.txt'}),\n",
              " Document(page_content='Workflow A JSON Import block has been added to enable datasets in JSON-formatted files to be imported into a Workflow. A Parameter Import block has been added to enable parameters to be imported into a Workflow as a dataset. A Deduplicate block has been added to enable duplicate observations to be removed from an input dataset. A Text Transform block has been added to enable text variables in an input dataset to be modified. The Hub group now includes: A Program Inputs block that enables Workflow parameters to be used in an executable deployment services program. A Program Results block that provides the results of an executable deployment services program to a Workflow. The Hub Program block is superseded by the Program Inputs and Program Results for defining input variables to, and results from, a deployment services program. The Database Explorer view can now be used to connect to Google BigQuery, Teradata, and Hadoop database servers. Variables from a dataset can now be grouped together for faster selection of the same multiple variables in Workflow blocks.', metadata={'source': 'skyscanner/question_1.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conversational Chain"
      ],
      "metadata": {
        "id": "q3tBRMmuOn3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "### Instruction: You're a travelling support agent that is talking to a customer. Use only the chat history and the following information\n",
        "{context}\n",
        "to answer ina helpful manner to the question. If you don't know the answer - say that you don't know.\n",
        "Keep your replies short, compassionate and informative.\n",
        "{chat_history}\n",
        "### Input: {question}\n",
        "### Response:\n",
        "\"\"\".strip()"
      ],
      "metadata": {
        "id": "7aiZjffiN0P4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"context\", \"question\", \"chat_history\"], template=template\n",
        ")"
      ],
      "metadata": {
        "id": "ZnjKz94fPbeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    human_prefix=\"### Input\",\n",
        "    ai_prefix=\"### Response\",\n",
        "    output_key=\"answer\",\n",
        "    return_messages=True,\n",
        ")"
      ],
      "metadata": {
        "id": "8G-eDfCzPvYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=db.as_retriever(),\n",
        "    memory=memory,\n",
        "    combine_docs_chain_kwargs={\"prompt\": prompt},\n",
        "    return_source_documents=True,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "2mCZna8sQQrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How flight search works?\"\n",
        "answer = chain(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOr66sDOQQuD",
        "outputId": "4b4358e7-cf6c-4d0e-d1a3-954a8ada16b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.db.index.hnswlib:Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m### Instruction: You're a travelling support agent that is talking to a customer. Use only the chat history and the following information\n",
            "Workflow A JSON Import block has been added to enable datasets in JSON-formatted files to be imported into a Workflow. A Parameter Import block has been added to enable parameters to be imported into a Workflow as a dataset. A Deduplicate block has been added to enable duplicate observations to be removed from an input dataset. A Text Transform block has been added to enable text variables in an input dataset to be modified. The Hub group now includes: A Program Inputs block that enables Workflow parameters to be used in an executable deployment services program. A Program Results block that provides the results of an executable deployment services program to a Workflow. The Hub Program block is superseded by the Program Inputs and Program Results for defining input variables to, and results from, a deployment services program. The Database Explorer view can now be used to connect to Google BigQuery, Teradata, and Hadoop database servers. Variables from a dataset can now be grouped together for faster selection of the same multiple variables in Workflow blocks.\n",
            "\n",
            "SAS Language Support Support for the ODS POWERPOINT output destination. Both the ODSLIST and ODSTEXT procedures now support the DATA option of the procedure statement, the CELLSTYLE statement and the TRANSLATE statement. The IMPORT procedure now supports the STARTCOL, ENDCOL, STARTROW, and ENDROW statements. The HTTP procedure now supports the DEBUG statement. The SGPANEL procedure now supports the TEXT statement. The SGPLOT procedure now supports the TEXT, XAXISTABLE, and YAXISTABLE statements. The LOGISTIC procedure now supports the UNITS statement. Support for the MCMC procedure. Support for the MDC procedure. Support for the OPTLP procedure. Support for the ORTHOREG procedure. Support for the VARMAX procedure. Bulk insert functionality can now be used with ODBC connections to a Google BigQuery database. Connections to a Snowflake database can now use Key Pair Authentication and federated authentication.\n",
            "\n",
            "Q: What's new in Altair SLC Version 4.4 A: Altair SLC version 4.4.1 onwards is available for purchase under Altair Units using Altair Licensing.\n",
            "\n",
            "The Altair SLC 4.4 GA release contains new features and enhancements, and maintenance updates to existing functionality. Here are just a few headline items.\n",
            "to answer ina helpful manner to the question. If you don't know the answer - say that you don't know.\n",
            "Keep your replies short, compassionate and informative.\n",
            "\n",
            "### Input: How flight search works?\n",
            "### Response:\u001b[0m\n",
            "Flight search engines work by scanning through their databases of available flights based on specific criteria provided by users such as departure airport, arrival airport, travel dates, number of passengers, class of service, etc. They then display a list of matching flights along with relevant details like flight duration, layover time, stopovers, cost, and availability. Some popular flight search engines also allow users to filter their searches according to preferences like nonstop flights or those with layovers, preferred airlines, price range, and amenities.\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW7v6QTdQQxr",
        "outputId": "175cfee9-43d8-445c-8941-f144dbf7c69e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['question', 'chat_history', 'answer', 'source_documents'])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer[\"source_documents\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zP2wbReXQQ0N",
        "outputId": "8badd565-6425-4974-ad10-7795df350b56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Workflow A JSON Import block has been added to enable datasets in JSON-formatted files to be imported into a Workflow. A Parameter Import block has been added to enable parameters to be imported into a Workflow as a dataset. A Deduplicate block has been added to enable duplicate observations to be removed from an input dataset. A Text Transform block has been added to enable text variables in an input dataset to be modified. The Hub group now includes: A Program Inputs block that enables Workflow parameters to be used in an executable deployment services program. A Program Results block that provides the results of an executable deployment services program to a Workflow. The Hub Program block is superseded by the Program Inputs and Program Results for defining input variables to, and results from, a deployment services program. The Database Explorer view can now be used to connect to Google BigQuery, Teradata, and Hadoop database servers. Variables from a dataset can now be grouped together for faster selection of the same multiple variables in Workflow blocks.', metadata={'source': 'skyscanner/question_1.txt'}),\n",
              " Document(page_content='SAS Language Support Support for the ODS POWERPOINT output destination. Both the ODSLIST and ODSTEXT procedures now support the DATA option of the procedure statement, the CELLSTYLE statement and the TRANSLATE statement. The IMPORT procedure now supports the STARTCOL, ENDCOL, STARTROW, and ENDROW statements. The HTTP procedure now supports the DEBUG statement. The SGPANEL procedure now supports the TEXT statement. The SGPLOT procedure now supports the TEXT, XAXISTABLE, and YAXISTABLE statements. The LOGISTIC procedure now supports the UNITS statement. Support for the MCMC procedure. Support for the MDC procedure. Support for the OPTLP procedure. Support for the ORTHOREG procedure. Support for the VARMAX procedure. Bulk insert functionality can now be used with ODBC connections to a Google BigQuery database. Connections to a Snowflake database can now use Key Pair Authentication and federated authentication.', metadata={'source': 'skyscanner/question_1.txt'}),\n",
              " Document(page_content=\"Q: What's new in Altair SLC Version 4.4 A: Altair SLC version 4.4.1 onwards is available for purchase under Altair Units using Altair Licensing.\\n\\nThe Altair SLC 4.4 GA release contains new features and enhancements, and maintenance updates to existing functionality. Here are just a few headline items.\", metadata={'source': 'skyscanner/question_1.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"I bought flight tickets, but I can't find any confirmation. Where is it?\"\n",
        "response = chain(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAtXsNC-RLfM",
        "outputId": "d5345272-44d5-4b06-a16a-c7907a3ef199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "\n",
            "Human: How flight search works?\n",
            "Assistant: Flight search engines work by scanning through their databases of available flights based on specific criteria provided by users such as departure airport, arrival airport, travel dates, number of passengers, class of service, etc. They then display a list of matching flights along with relevant details like flight duration, layover time, stopovers, cost, and availability. Some popular flight search engines also allow users to filter their searches according to preferences like nonstop flights or those with layovers, preferred airlines, price range, and amenities.\n",
            "Follow Up Input: I bought flight tickets, but I can't find any confirmation. Where is it?\n",
            "Standalone question:\u001b[0m\n",
            "Can you help me locate my flight ticket confirmation?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.db.index.hnswlib:Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m### Instruction: You're a travelling support agent that is talking to a customer. Use only the chat history and the following information\n",
            "Q: What's new in Altair SLC Version 4.4 A: Altair SLC version 4.4.1 onwards is available for purchase under Altair Units using Altair Licensing.\n",
            "\n",
            "The Altair SLC 4.4 GA release contains new features and enhancements, and maintenance updates to existing functionality. Here are just a few headline items.\n",
            "\n",
            "SAS Language Support Support for the ODS POWERPOINT output destination. Both the ODSLIST and ODSTEXT procedures now support the DATA option of the procedure statement, the CELLSTYLE statement and the TRANSLATE statement. The IMPORT procedure now supports the STARTCOL, ENDCOL, STARTROW, and ENDROW statements. The HTTP procedure now supports the DEBUG statement. The SGPANEL procedure now supports the TEXT statement. The SGPLOT procedure now supports the TEXT, XAXISTABLE, and YAXISTABLE statements. The LOGISTIC procedure now supports the UNITS statement. Support for the MCMC procedure. Support for the MDC procedure. Support for the OPTLP procedure. Support for the ORTHOREG procedure. Support for the VARMAX procedure. Bulk insert functionality can now be used with ODBC connections to a Google BigQuery database. Connections to a Snowflake database can now use Key Pair Authentication and federated authentication.\n",
            "\n",
            "Workflow A JSON Import block has been added to enable datasets in JSON-formatted files to be imported into a Workflow. A Parameter Import block has been added to enable parameters to be imported into a Workflow as a dataset. A Deduplicate block has been added to enable duplicate observations to be removed from an input dataset. A Text Transform block has been added to enable text variables in an input dataset to be modified. The Hub group now includes: A Program Inputs block that enables Workflow parameters to be used in an executable deployment services program. A Program Results block that provides the results of an executable deployment services program to a Workflow. The Hub Program block is superseded by the Program Inputs and Program Results for defining input variables to, and results from, a deployment services program. The Database Explorer view can now be used to connect to Google BigQuery, Teradata, and Hadoop database servers. Variables from a dataset can now be grouped together for faster selection of the same multiple variables in Workflow blocks.\n",
            "to answer ina helpful manner to the question. If you don't know the answer - say that you don't know.\n",
            "Keep your replies short, compassionate and informative.\n",
            "\n",
            "Human: How flight search works?\n",
            "Assistant: Flight search engines work by scanning through their databases of available flights based on specific criteria provided by users such as departure airport, arrival airport, travel dates, number of passengers, class of service, etc. They then display a list of matching flights along with relevant details like flight duration, layover time, stopovers, cost, and availability. Some popular flight search engines also allow users to filter their searches according to preferences like nonstop flights or those with layovers, preferred airlines, price range, and amenities.\n",
            "### Input:  Can you help me locate my flight ticket confirmation?\n",
            "### Response:\u001b[0m\n",
            "Of course! Please provide me with your booking reference number and/or your last name, so I can assist you better.\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QA Chain with Memory"
      ],
      "metadata": {
        "id": "TX6vN9DJRjyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    human_prefix=\"### Input\",\n",
        "    ai_prefix=\"### Response\",\n",
        "    input_key=\"question\",\n",
        "    output_key=\"answer\",\n",
        "    return_messages=True,\n",
        ")\n",
        "\n",
        "chain = load_qa_chain(\n",
        "    llm, chain_type=\"stuff\", prompt=prompt, memory=memory, verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "M22yw8-nRLhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Tell about Altair SLC documentation\"\n",
        "docs = db.similarity_search(question)\n",
        "answer = chain.run({\"input_documents\": docs, \"question\": question})\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 844
        },
        "id": "ok6Q0GxvRLkO",
        "outputId": "2f52ec02-bb77-4778-9c1a-64870545bafe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.db.index.hnswlib:Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m### Instruction: You're a travelling support agent that is talking to a customer. Use only the chat history and the following information\n",
            "Q: What's new in Altair SLC Version 4.4 A: Altair SLC version 4.4.1 onwards is available for purchase under Altair Units using Altair Licensing.\n",
            "\n",
            "The Altair SLC 4.4 GA release contains new features and enhancements, and maintenance updates to existing functionality. Here are just a few headline items.\n",
            "\n",
            "SAS Language Support Support for the ODS POWERPOINT output destination. Both the ODSLIST and ODSTEXT procedures now support the DATA option of the procedure statement, the CELLSTYLE statement and the TRANSLATE statement. The IMPORT procedure now supports the STARTCOL, ENDCOL, STARTROW, and ENDROW statements. The HTTP procedure now supports the DEBUG statement. The SGPANEL procedure now supports the TEXT statement. The SGPLOT procedure now supports the TEXT, XAXISTABLE, and YAXISTABLE statements. The LOGISTIC procedure now supports the UNITS statement. Support for the MCMC procedure. Support for the MDC procedure. Support for the OPTLP procedure. Support for the ORTHOREG procedure. Support for the VARMAX procedure. Bulk insert functionality can now be used with ODBC connections to a Google BigQuery database. Connections to a Snowflake database can now use Key Pair Authentication and federated authentication.\n",
            "\n",
            "Workflow A JSON Import block has been added to enable datasets in JSON-formatted files to be imported into a Workflow. A Parameter Import block has been added to enable parameters to be imported into a Workflow as a dataset. A Deduplicate block has been added to enable duplicate observations to be removed from an input dataset. A Text Transform block has been added to enable text variables in an input dataset to be modified. The Hub group now includes: A Program Inputs block that enables Workflow parameters to be used in an executable deployment services program. A Program Results block that provides the results of an executable deployment services program to a Workflow. The Hub Program block is superseded by the Program Inputs and Program Results for defining input variables to, and results from, a deployment services program. The Database Explorer view can now be used to connect to Google BigQuery, Teradata, and Hadoop database servers. Variables from a dataset can now be grouped together for faster selection of the same multiple variables in Workflow blocks.\n",
            "to answer ina helpful manner to the question. If you don't know the answer - say that you don't know.\n",
            "Keep your replies short, compassionate and informative.\n",
            "[]\n",
            "### Input: Tell about Altair SLC documentation\n",
            "### Response:\u001b[0m\n",
            "Altair SLC documentation covers various topics such as installation, licensing, getting started, user guides, reference manuals, tutorials, webinars, videos, FAQs, and more. It helps users understand how to use Altair SLC software effectively and efficiently. The documentation is organized in different sections, making it easy for users to find what they need quickly. Additionally, Altair offers technical support to help users resolve any issues they encounter while working with Altair SLC software.\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-2b112717302f>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Tell about Altair SLC documentation\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"input_documents\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"question\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`run` supports only one positional argument.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             return self(args[0], callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[0m\u001b[1;32m    441\u001b[0m                 \u001b[0m_output_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         final_outputs: Dict[str, Any] = self.prep_outputs(\n\u001b[0m\u001b[1;32m    246\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_only_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mprep_outputs\u001b[0;34m(self, inputs, outputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_only_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/memory/chat_memory.py\u001b[0m in \u001b[0;36msave_context\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;34m\"\"\"Save context from this conversation to buffer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0minput_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_input_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_user_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_ai_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/memory/chat_memory.py\u001b[0m in \u001b[0;36m_get_input_output\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0moutput_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprompt_input_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'answer'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Owq1cZ5ERL7U"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}